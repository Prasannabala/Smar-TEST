# âš¡ Smar-Test

**Smart + Test = Smartest Test Case Generation**

A professional-grade AI-powered tool for generating comprehensive test cases from requirements documents using advanced LLMs.

## Features

- **Multiple LLM Support**:
  - Ollama (local)
  - Hugging Face
  - OpenAI
  - Groq
  - Anthropic
- **Client Context Management**: Store client-specific rules, navigation patterns, and best practices
- **Comprehensive Test Generation**:
  - Manual Test Cases
  - Gherkin BDD Feature Files
  - Selenium Python Scripts
  - Playwright JavaScript Tests
- **Multiple Export Formats**: Excel, CSV, Markdown
- **Modern UI**: Clean, intuitive interface
- **Secure & Private**: All data stored locally in `~/.smar-test/`

## Quick Start

### Prerequisites

- Python 3.9+
- pip package manager
- Your favorite IDE (VS Code, PyCharm, etc.)

### Installation

1. **Clone the repository**:
```bash
git clone https://github.com/Prasannabala/Smar-TEST.git
cd Smar-TEST
```

2. **Create virtual environment**:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Run the application**:
```bash
streamlit run app.py
```

5. **Access the UI**:
   - Opens automatically in your browser at `http://localhost:8501`
   - Or manually navigate to that URL

## First Time Setup

### 1. Create a User Account
- Enter your username to isolate your workspace
- Your data will be stored in `~/.smar-test/`

### 2. Configure LLM Settings
- Click "âš™ï¸ LLM Settings" in sidebar
- Select your LLM provider (Ollama, OpenAI, Groq, etc.)
- Configure provider-specific settings
- Click "Save Settings"

### 3. (Optional) Set Up Client Context
- Click "ğŸ’¼ Client Setup" in sidebar
- Create a new client with project details
- Add navigation rules, business rules, best practices
- Upload context documents if needed

### 4. Generate Test Cases
- Click "ğŸš€ Generate Tests" in sidebar
- Upload your requirements document
- Select test types to generate
- Click "Generate Test Cases"
- Review and export results

## Data Storage

All your data is stored **locally** on your machine:

```
~/.smar-test/
â”œâ”€â”€ settings.json          # Your LLM configuration
â”œâ”€â”€ app.db                 # Client data and history
â”œâ”€â”€ clients/               # Client-specific files
â””â”€â”€ exports/               # Generated test files
```

**Benefits:**
- âœ… Your data stays on your computer
- âœ… No data sent to any servers
- âœ… Works completely offline
- âœ… Easy to backup

## API Keys & Security

API keys for cloud LLM providers (OpenAI, Groq, etc.) should be provided via **environment variables**:

```bash
# Set environment variables
export OPENAI_API_KEY="sk-..."
export GROQ_API_KEY="gsk_..."
export ANTHROPIC_API_KEY="sk-ant-..."

# Then run the app
streamlit run app.py
```

Or create a `.env` file:
```
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
ANTHROPIC_API_KEY=sk-ant-...
```

**Important**: API keys are never saved to disk and are only used during the session.

## Project Structure

```
Smar-TEST/
â”œâ”€â”€ app.py                    # Main Streamlit application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚
â”œâ”€â”€ config/                   # Configuration modules
â”‚   â”œâ”€â”€ settings.py          # Application settings
â”‚   â”œâ”€â”€ settings_manager.py  # Settings persistence
â”‚   â”œâ”€â”€ user_session.py      # User authentication
â”‚   â””â”€â”€ llm_config.py        # LLM configurations
â”‚
â”œâ”€â”€ core/                     # Core functionality
â”‚   â”œâ”€â”€ llm_adapter.py       # LLM provider adapters
â”‚   â”œâ”€â”€ document_parser.py   # Document parsing
â”‚   â”œâ”€â”€ test_generator.py    # Test generation engine
â”‚   â””â”€â”€ export_handler.py    # Export functionality
â”‚
â”œâ”€â”€ models/                   # Data models
â”‚   â”œâ”€â”€ client_context.py    # Client context
â”‚   â”œâ”€â”€ test_case.py         # Test case models
â”‚   â””â”€â”€ requirement.py       # Requirement model
â”‚
â”œâ”€â”€ storage/                  # Data persistence
â”‚   â”œâ”€â”€ database.py          # SQLite database
â”‚   â””â”€â”€ file_manager.py      # File management
â”‚
â””â”€â”€ ui/                       # User interface
    â”œâ”€â”€ components.py        # UI components
    â””â”€â”€ styles.py            # Styling
```

## LLM Providers

### Ollama (Local - Recommended)
- Free and runs on your computer
- No API key needed
- Works offline
- Supports: Mistral, Llama, Qwen, etc.

Setup:
```bash
ollama pull mistral:latest
ollama serve  # Keep running in separate terminal
```

### OpenAI
- Requires API key
- Models: GPT-4, GPT-3.5
- Get key: https://platform.openai.com/api-keys

### Groq
- Requires API key
- Fast inference
- Free tier available
- Get key: https://console.groq.com/keys

### Anthropic
- Requires API key
- Claude models
- Get key: https://console.anthropic.com

### Hugging Face
- Requires API token (optional for public models)
- Many open-source models
- Get token: https://huggingface.co/settings/tokens

## Testing Workflow

1. **Prepare requirements document** (TXT, PDF, or DOCX)
2. **Add client context** (optional but recommended)
3. **Configure LLM settings**
4. **Upload requirements** to the app
5. **Select test types** to generate
6. **Review generated tests**
7. **Export in preferred format**
8. **Import to your test management system**

## Security & Privacy

- âœ… All data stored locally on your machine
- âœ… API keys never saved to disk
- âœ… User authentication for workspace isolation
- âœ… No data sent to external servers (except LLM API calls)
- âœ… Complete control over your data

See `SECURITY.md` for detailed security documentation.

## Troubleshooting

### Issue: "Port 8501 already in use"
```bash
streamlit run app.py --server.port 8502
```

### Issue: "Module not found"
```bash
# Ensure virtual environment is activated
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Issue: "Ollama connection refused"
```bash
# Start Ollama in a separate terminal
ollama serve
```

### Issue: "API key not recognized"
```bash
# Verify environment variable is set
echo $OPENAI_API_KEY  # On Windows: echo %OPENAI_API_KEY%
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

MIT License - feel free to use and modify.

## Support

For issues and feature requests, please open a GitHub issue.

---

**Happy testing! ğŸš€**
